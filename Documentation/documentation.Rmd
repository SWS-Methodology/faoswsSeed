---
title: "Seed module"
author: "Francesca"
date: "October 20, 2016"
header-includes:
   - \usepackage{bbm}
   - \usepackage{booktabs}
   - \usepackage{color}
output: pdf_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction



## How to use this document

This document is intended as a guide to understand more in detail the approach used in the seed module. It describes the most updated version of the module and it provides to the reader the state of the art in terms of methodology reflected into functionalities already implemented though R routines.

In the following we explicitly make reference to R programming language in order to guide the reader also in a deepper understanding of the functions stored in the Seed module repository [link](https://github.com/SWS-Methodology/faoswsSeed).


```{r, echo=FALSE}

suppressMessages({
  library(bit64)
  library(curl)
  library(faosws)
  library(faoswsUtil)
  library(lme4)
  library(data.table)
  library(magrittr)
  library(reshape2)
  library(igraph)
  library(plyr)
  library(dplyr)
  ##library(RJDBC)
  library(ggplot2)
  library(faoswsFlag)
  library(faoswsProcessing)
  library(splines)
  library(faoswsImputation)
  library(faoswsEnsure)
  library(faosws)
  library(lattice)
  
})

library(faoswsSeed)
```



Setting up variables:

```{r, echo=FALSE}
areaVar = "geographicAreaM49"
yearVar = "timePointYears"
itemVar = "measuredItemCPC"
elementVar = "measuredElement"
areaSownElementCode = "5025"
areaHarvestedElementCode = "5312"
seedElementCode = "5525"
valuePrefix = "Value_measuredElement_"
flagObsPrefix = "flagObservationStatus_measuredElement_"
flagMethodPrefix = "flagMethod_measuredElement_"


updateModel = TRUE
```



```{r, echo=FALSE}
if(CheckDebug()){
    library(faoswsModules)
  SETTINGS <- ReadSettings("sws.yml")
  SetClientFiles(SETTINGS[["certdir"]])
  
  GetTestEnvironment(baseUrl = SETTINGS[["server"]],
                     token = SETTINGS[["token"]])
  
}

updateModel = TRUE
```


## The model

As mentioned above, FAO collects data for seed and area sown through the FAO production questionnaire. However, while overall response rates to the questionnaire have been rising, not all countries provide estimates for all commodities.  Where no official seed use information is available, seed use can be imputed, including by national FBS compilers. In practice, the necessary steps are:

\begin{itemize}

\item	Impute area sown, when missing.
\item	Estimate seed use through a hierarchical linear model (if official data collected thaks to questionnaire is unavailable).

\end{itemize}



The estimation of seed rates is performed via a hierarchical linear model.  The rationale for this model is that it is capable of capturing and modelling complicated trends when data is available.  Moreover, the hierarchy of the model allows accurate imputation on countries with very sparse data by pooling together global data.  The mathematical model can be written as follows:


$$ log(Se_{i,j,k})=\beta_{0} +\beta_{1} Temp_{i}+\beta_{2}Time+\beta_{3,j,k}(AreaSown_{i,j,k}+\epsilon_{i,j,k}$$


$$\beta_{3,j,k}=\gamma_{3,0}+\gamma_{3,1,j,k}(CPC:Country)_{j,k}+\delta_{j,k} $$


$$\gamma_{3,1,j}=k_{3,1,0}+k_{3,1,1}(CPC)_j+\phi_{j}$$




Thus, the model estimates seed use proportional to the area sown.  The model also accounts for changes over time and differences across countries; the latter are captured by the annual temperature variable, assuming essentially that seed rates need to be higher where production conditions are difficult, with a potential of late and frequent frosts (Russia), and can be lower where production conditions are more favourable (UK).  

```{r echo=F}

knitr::include_graphics("C:/Users/Rosa/Favorites/Github/sws_project/faoswsSeed/documentation/SeedModuleFlowChart.pdf")

```

The flowchart highlights all the data that we have to pull from the database (with ther relative sources).  necessary to performed the imputation based on the hierarchical linear model. In particular we need

\begin{itemize}
\item Official seed data (response variable)
\item AreaSown data to be derived from areaHarvested (covariate)
\item Climate data to take into account the temperature to catch the country specificity (covariate)


\end{itemize}


## Seed data
Import Official seed data:

```{r }
seed = getOfficialSeedData()
head(seed)
```

Once seed has been pulled from the DataBase, the R module includes many functions from the Ensure package in order to performe a preliminary data validation.
The checks are mainly addressed to:

1) ensure that the pulled data are in realible ranges: seed (5525) cannot be negative.


```{r }
  ensureValueRange(data = seed,
                   ensureColumn = "Value_measuredElement_5525",
                   min = 0,
                   max = Inf,
                   includeEndPoint = TRUE,
                   returnData = FALSE,
                   getInvalidData = FALSE)
  
  
```

2) ensure flag validity: this check might be unecessary because the getOfficialSeedData function embeds infomation in flags to be pulled:
```{r eval=FALSE}
   protectedFlag <- flagValidTable[flagValidTable$Protected == TRUE,] %>%
    .[, flagCombination := paste(flagObservationStatus, flagMethod, sep = ";")]
    
```

```{r echo=F}
  ensureFlagValidity(data = seed,
                    flagObservationVar = "flagObservationStatus_measuredElement_5525",
                      flagMethodVar = "flagMethod_measuredElement_5525",
                      returnData = FALSE,
                      getInvalidData = FALSE)
  
``` 
 
 
```{r }
  ##Ensure   CorrectMissingValue not necessary because I pull only official data whose ObservationFlag is ""
  
  ensureCorrectMissingValue(data = seed,
                            valueVar = "Value_measuredElement_5525",
                            flagObservationStatusVar = "flagObservationStatus_measuredElement_5525",
                            missingObservationFlag = "M",
                            returnData = FALSE,
                            getInvalidData = FALSE)
  
```


The seed data are then cleaned in order to:
\begin{itemize}

\item remove previous estimations besed on the carry forward procedure 
\item add three additional columns the CPC hierachy (the need of this passage will be clear when we build the model)

\end{itemize}

```{r }
seed = removeCarryForward(data = seed,
                            variable = "Value_measuredElement_5525")
  
seed = buildCPCHierarchy(data = seed, cpcItemVar = itemVar, levels = 3)
```


## Area data

 
Two additional variables are requested in order to build the model. Seed use depends on the area sown. Unfortunatly we do not have high quality data about area sown, in the following is described the procedure to estimate areaSown starting from areaHarvested. The following table shows the first 6 lines of the area data matrix, just to give an idea of its content.     
  
```{r }
area = getAllAreaData()
head(area)
  
```   
  

We report the structure of the area data matrix in order to summarise the name of columns (note 5312=area harvested; 5025= area sown)


```{r, echo=FALSE }  
str(area)
```  

We perform the same quality checks already run for the OfficialSeedData. In particular:  
  
```{r, echo=TRUE } 
 
 areaPreProcessed= preProcessing(data= area,
                                 normalised = FALSE)
 
 
 
 areaConflict =areaRemoveZeroConflict(areaPreProcessed,
                                      value1= "Value_measuredElement_5025",
                                      value2= "Value_measuredElement_5312",
                                      observationFlag1= "flagObservationStatus_measuredElement_5025",
                                      methodFlag1= "flagMethod_measuredElement_5025",
                                      missingObservationFlag = "M",
                                      missingMethodFlag = "u"
 )
 
 
  ensureValueRange(data = areaConflict,
                   ensureColumn = "Value_measuredElement_5312",
                   min = 0,
                   max = Inf,
                   includeEndPoint = TRUE,
                   returnData = FALSE,
                   getInvalidData = FALSE)
  
  
  ensureValueRange(data = areaConflict,
                   ensureColumn = "Value_measuredElement_5025",
                   min = 0,
                   max = Inf,
                   includeEndPoint = TRUE,
                   returnData = FALSE,
                   getInvalidData = FALSE)
  
  
  

areaConflictNormalised= normalise (areaConflict)

```   

Unfortunatly, when we performe the flag validation procedure, the ensureFlagValidity function highlightes that there are still invalid flag combinations.

```{r , echo=FALSE} 



invalid=   ensureFlagValidity(areaConflictNormalised,
                              normalised =TRUE,
                              getInvalidData = TRUE)


unique(invalid[,.(flagObservationStatus,flagMethod)])



table(invalid[,.(flagObservationStatus,flagMethod)])


flagValidTable[flagObservationStatus=="E" & flagMethod=="e",]
flagValidTable[flagObservationStatus=="E" & flagMethod=="p",]


```

It is evided the need to embed into the R module some authocorrection functions (very similar to the routine already developed in the production module) whose effects are: 




```{r, echo=FALSE}


autoFlagCorrection = function(data,
                              value= "Value",
                              flagObservationStatusVar = "flagObservationStatus",
                              flagMethodVar = "flagMethod"){
  dataCopy = copy(data)
  
  ## Correction (): (, ) --> (M, u)
  
  
  correctionFilter =
    dataCopy[[flagObservationStatusVar]] == "" &
    dataCopy[[flagMethodVar]] == ""
  
  dim2=dim(dataCopy[correctionFilter,])
  message("Number of (E, t) replaced with (E, -)", dim2[1])
  
  
  dataCopy[correctionFilter,
           `:=`(c(value,flagObservationStatusVar, flagMethodVar),
                .(NA_real_,"M", "u"))]
  
  ## Correction (2): (E, t) --> (E, -)
  
  
  correctionFilter =
    dataCopy[[flagObservationStatusVar]] == "E" &
    dataCopy[[flagMethodVar]] == "t"
  
  dim2=dim(dataCopy[correctionFilter,])
  message("Number of (E, t) replaced with (E, -)", dim2[1])
  
  
  
  dataCopy[correctionFilter,
           `:=`(c(flagObservationStatusVar, flagMethodVar),
                .("E", "-"))]
  
  ## Correction (3): (E, e) --> (I, e)
  correctionFilter =
    dataCopy[[flagObservationStatusVar]] == "E" &
    dataCopy[[flagMethodVar]] == "e"
  
  
  dim3=dim(dataCopy[correctionFilter,])
  message("Number of (E, e) replaced with (I, e)", dim3[1])
  
  dataCopy[correctionFilter,
           `:=`(c(flagObservationStatusVar, flagMethodVar),
                .("I", "e"))]
  
  ## Correction (4): (E, p) --> (E, f)
  correctionFilter =
    dataCopy[[flagObservationStatusVar]] == "E" &
    dataCopy[[flagMethodVar]] == "p"
  
  
  dim4=dim(dataCopy[correctionFilter,])
  message("Number of (E, p) replaced with (E, f)", dim4[1])
  
  
  dataCopy[correctionFilter,
           `:=`(c(flagObservationStatusVar, flagMethodVar),
                .("E", "f"))]
  
  dataCopy
  
  ##   data.table(dim1[1],dim2[1],dim3[1],dim4[1])
  
  
}

areaConflictNormalised=autoFlagCorrection(areaConflictNormalised)




areaCleaned=denormalise(areaConflictNormalised, denormaliseKey = "measuredElement")



```


## Imputation of Area Sown


To impute the actual area sown, the following approach is taken:
\begin{itemize}
\item	If values of the area sown and the area harvested are available, then an average ratio of the area sown to the area harvested is computed.
  Then, if the area sown is unavailable in one year, it is imputed by multiplying the area harvested in the following year by the average ratio.
  The idea is that the areaSown is always equal or greater than areaHarvested. 
The ratio represents the factor to be multiplied to the available areaHarvested in order to obtain the areaSown. 
The avarage is computed by Country-Commodity combinations. The discrepancy between areaSown 
and areaHarvested is strictly dependent on the commodity and some evironmental factors (climate, kind of soil..)

\item	If no prior information on the area sown is available or the ratio is erroneosly lower that 1, the corrective factors are imposed equal to 1
 and consequently the area sown is assumed to be equal to the area harvested.
\end{itemize}


We show some lines of the dataset containg area data

```{r, echo=FALSE}  
imputedArea=imputeAreaSown(data = areaCleaned,
                             byKey= c("geographicAreaM49","measuredItemCPC"))

imputedArea
```





## Climate data
We pull climate data from the World Bank DB, and we fill the missing values with the average temperature (computed by country). 

We are now ready to merge all tha data in a unique data table containing all the input for the model.



```{r, echo=FALSE}
  climate = getWorldBankClimateData()  
    
  

  
  finalModelData = mergeAllSeedData(seedData = seed, imputedArea, climate)
  
  
## Extrapolate climateData: it means to fill the emply cells with the average temperature
  
   
  meanTEMP=aggregate(finalModelData[!is.na(Value_wbIndicator_SWS.FAO.TEMP),Value_wbIndicator_SWS.FAO.TEMP],
             by=list(finalModelData[!is.na(Value_wbIndicator_SWS.FAO.TEMP),geographicAreaM49]),FUN="mean")
  colnames(meanTEMP)=c("geographicAreaM49","Value_wbIndicator_SWS.FAO.TEMP_mean")
  finalModelData=merge(finalModelData, meanTEMP, by="geographicAreaM49")
  finalModelData[is.na(Value_wbIndicator_SWS.FAO.TEMP) ,
                 Value_wbIndicator_SWS.FAO.TEMP :=  Value_wbIndicator_SWS.FAO.TEMP_mean]
  
  finalModelData[,Value_wbIndicator_SWS.FAO.TEMP_mean:=NULL]
  
 
  

  finalModelData = finalModelData[Value_measuredElement_5525 > 1 &
                                      Value_measuredElement_5025 >1, ]
  ## We have to remove cases where we do not have temperature, as we cannot create
  ## a model when independent variables are missing.  The predictions would be NA
  ## anyways, and so we wouldn't be saving anything to the database if we left
  ## them in.
  
  

  
  
  finalModelData = finalModelData[!is.na(Value_wbIndicator_SWS.FAO.TEMP), ]
  
```


We are now ready to perform the imputation. The finalModelData containd all the ingredients..



````{r}
head(finalModelData)

````







````{r}


seedLmeModel = 
    lmer(log(Value_measuredElement_5525) ~ Value_wbIndicator_SWS.FAO.TEMP +
           timePointYears + 
           (log(Value_measuredElement_5025)|cpcLvl3/measuredItemCPC:geographicAreaM49),
         data = finalModelData)

````

```{r, echo=FALSE}


seed1 = getSelectedSeedData()

seed1= preProcessing(data= seed1, normalised = FALSE)

##seed = removeCarryForward(data = seed, variable = "Value_measuredElement_5525")




##seedRemoved=removeNonProtectedFlag(seed,normalised = FALSE)

##ensureFlagValidity(seed1,normalised = FALSE, getInvalidData = FALSE)



seed1 = removeCarryForward(data = seed1, variable = "Value_measuredElement_5525")
seed1 = buildCPCHierarchy(data = seed1, cpcItemVar = itemVar, levels = 3)

finalPredictData = mergeAllSeedData(seedData = seed1, imputedArea, climate)



finalPredictData = finalPredictData[Value_measuredElement_5525 > 1 &
                                      Value_measuredElement_5025 > 1, ]


## We have to remove cases where we do not have temperature, as we cannot create
## a model when independent variables are missing.  The predictions would be NA
## anyways, and so we wouldn't be saving anything to the database if we left
## them in.

meanTEMP1=aggregate(finalPredictData[!is.na(Value_wbIndicator_SWS.FAO.TEMP),Value_wbIndicator_SWS.FAO.TEMP],
                   by=list(finalPredictData[!is.na(Value_wbIndicator_SWS.FAO.TEMP),geographicAreaM49]),FUN="mean")

colnames(meanTEMP1)=c("geographicAreaM49","Value_wbIndicator_SWS.FAO.TEMP_mean")

finalPredictData=merge(finalPredictData, meanTEMP1, by="geographicAreaM49")
finalPredictData[is.na(Value_wbIndicator_SWS.FAO.TEMP) ,
               Value_wbIndicator_SWS.FAO.TEMP :=  Value_wbIndicator_SWS.FAO.TEMP_mean]

finalPredictData[,Value_wbIndicator_SWS.FAO.TEMP_mean:=NULL]



##finalPredictData = finalPredictData[!is.na(Value_wbIndicator_SWS.FAO.TEMP), ]


## Impute selected data

finalPredictData[, predicted := exp(predict(seedLmeModel,
                                            newdata = finalPredictData,
                                            allow.new.levels = TRUE))]

 xyplot(predicted~Value_measuredElement_5525, data=finalPredictData,
       auto.key=list(space="top", columns=length(unique(finalPredictData[,measuredItemCPC])), 
       title="District", cex.title=1,
       lines=TRUE, points=FALSE)
          )

 
````

